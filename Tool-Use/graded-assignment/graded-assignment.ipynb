{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb40170",
   "metadata": {},
   "source": [
    "# Graded Lab : Tool Use and Reflective Agents\n",
    "\n",
    "In this lab, you will explore how AI agents can enhance research workflows by leveraging external tools and engaging in critical self-reflection. You'll learn how to build and integrate callable tools‚Äîsuch as web and academic search functions, and connect them to a language model using OpenAI's tool-calling API. Then, you‚Äôll guide the agent to not only generate content but also **reflect** on its own output, improving the quality and depth of the final report. By the end of this lab, you will have implemented a mini agent capable of searching, reasoning, and publishing structured reports in HTML‚Äîlaying the foundation for more advanced multi-step and autonomous AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ede51",
   "metadata": {},
   "source": [
    "### üéØ Learning Objectives\n",
    "\n",
    "By the end of this lab, you can:\n",
    "- Chain steps into a research pipeline (**search ‚Üí reflection ‚Üí formatting**).\n",
    "- Convert natural-language output into **styled HTML** suitable for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08fc44",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to write your solution code or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "* To submit your notebook for grading, first save it by clicking the üíæ icon on the top left of the page and then click on the <span style=\"background-color: red; color: white; padding: 3px 5px; font-size: 16px; border-radius: 5px;\">Submit assignment</span> button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22668fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 421,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Standard library imports\n",
    "# ================================\n",
    "import json\n",
    "\n",
    "# ================================\n",
    "# Third-party imports\n",
    "# ================================\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# ================================\n",
    "# Local / project imports\n",
    "# ================================\n",
    "import research_tools\n",
    "\n",
    "# ================================\n",
    "# Environment setup\n",
    "# ================================\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Instantiate OpenAI's client (you should use this in your graded functions)\n",
    "CLIENT = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe40a79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 30
   },
   "outputs": [],
   "source": [
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1bef",
   "metadata": {},
   "source": [
    "## Using Tools\n",
    "\n",
    "You‚Äôll use two research tools exposed in the `research_tools` module:\n",
    "- **`arxiv_search_tool(query, max_results)`** ‚Äì academic papers via arXiv API.\n",
    "- **`tavily_search_tool(query, max_results, include_images)`** ‚Äì general web search via Tavily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacac323",
   "metadata": {},
   "source": [
    "Let's explore how the `arxiv_search_tool` works.\n",
    "\n",
    "This tool searches arXiv and returns a list of papers with:\n",
    "- `title`, `authors`, `published`, `summary`, `url`, and (if available) `link_pdf`.\n",
    "\n",
    "Below, we run a quick test and print the results in a readable format. Next cell is editable so feel free to try some search queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d0eded",
   "metadata": {
    "deletable": false,
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Paper 1\n",
      "  Title     : On Associative Conformal Algebras of Linear Growth\n",
      "  Authors   : Alexander Retakh\n",
      "  Published : 2000-05-25\n",
      "  URL       : http://arxiv.org/abs/math/0005258v1\n",
      "\n",
      "üìÑ Paper 2\n",
      "  Title     : Linear algebra meets Lie algebra: the Kostant-Wallach theory\n",
      "  Authors   : Noam Shomron, Beresford N. Parlett\n",
      "  Published : 2008-09-07\n",
      "  URL       : http://arxiv.org/abs/0809.1204v2\n",
      "\n",
      "üìÑ Paper 3\n",
      "  Title     : On associative conformal algebras of linear growth II\n",
      "  Authors   : Alexander Retakh\n",
      "  Published : 2002-12-12\n",
      "  URL       : http://arxiv.org/abs/math/0212168v1\n",
      "\n",
      "\n",
      "üßæ Raw arxiv_Results:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"title\": \"On Associative Conformal Algebras of Linear Growth\",\n",
      "    \"authors\": [\n",
      "      \"Alexander Retakh\"\n",
      "    ],\n",
      "    \"published\": \"2000-05-25\",\n",
      "    \"url\": \"http://arxiv.org/abs/math/0005258v1\",\n",
      "    \"summary\": \"Lie conformal algebras appear in the theory of vertex algebras. Their\\nrelation is similar to that of Lie algebras and their universal enveloping\\nalgebras. Associative conformal algebras play a role in conformal\\nrepresentation theory. We introduce the notions of conformal identity and\\nunital associative conformal algebras and classify finitely generated simple\\nunital associative conformal algebras of linear growth. These are precisely the\\ncomplete algebras of conformal endomorphisms of finite modules.\",\n",
      "    \"link_pdf\": \"http://arxiv.org/pdf/math/0005258v1\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Linear algebra meets Lie algebra: the Kostant-Wallach theory\",\n",
      "    \"authors\": [\n",
      "      \"Noam Shomron\",\n",
      "      \"Beresford N. Parlett\"\n",
      "    ],\n",
      "    \"published\": \"2008-09-07\",\n",
      "    \"url\": \"http://arxiv.org/abs/0809.1204v2\",\n",
      "    \"summary\": \"In two languages, Linear Algebra and Lie Algebra, we describe the results of\\nKostant and Wallach on the fibre of matrices with prescribed eigenvalues of all\\nleading principal submatrices. In addition, we present a brief introduction to\\nbasic notions in Algebraic Geometry, Integrable Systems, and Lie Algebra aimed\\nat specialists in Linear Algebra.\",\n",
      "    \"link_pdf\": \"http://arxiv.org/pdf/0809.1204v2\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"On associative conformal algebras of linear growth II\",\n",
      "    \"authors\": [\n",
      "      \"Alexander Retakh\"\n",
      "    ],\n",
      "    \"published\": \"2002-12-12\",\n",
      "    \"url\": \"http://arxiv.org/abs/math/0212168v1\",\n",
      "    \"summary\": \"We classify unital associative conformal algebras of linear growth and\\nprovide new examples of such.\",\n",
      "    \"link_pdf\": \"http://arxiv.org/pdf/math/0212168v1\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test the arXiv search tool\n",
    "topic = \"linear algebra\"\n",
    "\n",
    "arxiv_results = research_tools.arxiv_search_tool(topic, max_results=3)\n",
    "\n",
    "# Show formatted arxiv_results\n",
    "for i, paper in enumerate(arxiv_results, 1):\n",
    "    if \"error\" in paper:\n",
    "        print(f\"‚ùå Error: {paper['error']}\")\n",
    "    else:\n",
    "        print(f\"üìÑ Paper {i}\")\n",
    "        print(f\"  Title     : {paper['title']}\")\n",
    "        print(f\"  Authors   : {', '.join(paper['authors'])}\")\n",
    "        print(f\"  Published : {paper['published']}\")\n",
    "        print(f\"  URL       : {paper['url']}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nüßæ Raw arxiv_Results:\\n\")\n",
    "print(json.dumps(arxiv_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fd399",
   "metadata": {},
   "source": [
    "The `tavily_search_tool` calls the Tavily API to fetch web results. Returns a list of dicts:\n",
    "- `title`, `content`, `url` (and optional image URLs when `include_images=True`).\n",
    "\n",
    "Run the cell to inspect sample output. Next cell is editable so feel free to try some search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e728e",
   "metadata": {
    "deletable": false,
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'What is Retrieval Augmented Generation (RAG)? | Databricks', 'content': 'Retrieval augmented generation, or RAG, is an architectural approach that can improve the efficacy of large language model (LLM) applications by leveraging custom data. This is called retrieval augmented generation (RAG), as you would retrieve the relevant data and use it as augmented context for the LLM. With RAG architecture, organizations can deploy any LLM model and augment it to return relevant results for their organization by giving it a small amount of their data without the costs and time of fine-tuning or pretraining the model. * Using MLflow AI Gateway and Llama 2 to Build Generative AI Apps (Achieve greater accuracy using retrieval augmented generation (RAG) with your own data) Contact Databricks to schedule a demo and talk to someone about your LLM and retrieval augmented generation (RAG) projects', 'url': 'https://www.databricks.com/glossary/retrieval-augmented-generation-rag'}\n",
      "{'title': 'What is Retrieval-Augmented Generation (RAG)? - Google Cloud', 'content': 'RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative [large language models (LLMs)](https://cloud.google.com/ai/llms). Data framework for developing context-augmented LLM applications, and facilitates retrieval-augmented generation (RAG.)](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview) * [APIs to build your own search and Retrieval Augmented Generation (RAG) systems](https://cloud.google.com/generative-ai-app-builder/docs/builder-apis) * [Infrastructure for a RAG-capable generative AI application using Vertex AI and Vector Search](https://cloud.google.com/architecture/gen-ai-rag-vertex-ai-vector-search) [Find a partner](https://cloud.google.com/find-a-partner/) * [Run your apps wherever you need them.](https://cloud.google.com/multicloud) Read what industry analysts say about us.](https://cloud.google.com/analyst-reports) Browse and download popular whitepapers.](https://cloud.google.com/whitepapers) AI-driven solutions to build and scale games faster.](https://cloud.google.com/solutions/games) Migration and AI tools to optimize the manufacturing value chain.](https://cloud.google.com/solutions/manufacturing) Data storage, AI, and analytics solutions for government agencies.](https://cloud.google.com/gov) * [Databases](https://cloud.google.com/products/databases)', 'url': 'https://cloud.google.com/use-cases/retrieval-augmented-generation'}\n",
      "{'title': 'Top Use Cases of Retrieval-Augmented Generation (RAG) in AI', 'content': \"* By integrating retrieval mechanisms with language generation, RAG systems produce more accurate and informative text outputs, significantly improving tasks like machine translation, question answering, and summarization. Retrieval augmented generation (RAG) is an artificial intelligence methodology that combines the power of neural language models with external knowledge resources to generate text that is relevant and informed. Retrieval augmented generation (RAG) operates by integrating a retrieval component into the language generation process, expanding the model's knowledge base beyond its initial training data. Retrieval augmented generation (RAG) significantly enhances the capabilities of natural language processing systems. For **question answering**, RAG employs its retrieval component to source relevant information before generating a response.\", 'url': 'https://www.glean.com/blog/retrieval-augmented-generation-use-cases'}\n",
      "{'title': \"RAG Tutorial: A Beginner's Guide to Retrieval Augmented Generation\", 'content': 'To elaborate further on Retrieval Augmented Generation, usually shortened to \"RAG\", it is a cutting-edge technique in artificial intelligence (AI) that combines the strengths of traditional language models with the ability to dynamically incorporate relevant external data. For an user query, RAG tends to retrieve the information from the provided source/information/data that is stored in a vector database. One simple use case would be the customer support application, where the custom data is fed to the application stored in a vector database and when a user query comes in, it generates the most appropriate response related to your products or services and not some generic answer. By integrating SingleStoreDB with the RAG model, you can harness the power of real-time analytics and fast data retrieval, ensuring that your chat application provides timely and relevant responses to user queries.', 'url': 'https://www.singlestore.com/blog/a-guide-to-retrieval-augmented-generation-rag/'}\n",
      "{'title': 'Retrieval Augmented Generation (RAG) ‚Äì 5 Use Cases - TheBlue.ai', 'content': 'In our last article, we discussed the impact of **Retrieval Augmented Generation (RAG)** systems in enhancing **Large Language Models (LLM)** by integrating dynamic information retrieval with generative processes. This new article will delve deeper into the practical applications of Retrieval Augmented Generation (RAG) systems, presenting five use cases across different industries and highlighting how these systems enhance data accessibility and streamline tasks and processes in real-world scenarios. **#2: Enhancing AI Avatars with Retrieval Augmented Generation (RAG)** Retrieval Augmented Generation (RAG) significantly improves AI avatars or digital humans by enabling them to access and utilize real-time, context-specific information during interactions. By integrating a retrieval component into generative models, RAG systems can pull from a vast repository of company-specific documents, training materials, and past queries to provide real-time, contextually relevant information to new hires.', 'url': 'https://theblue.ai/blog/rag-news/'}\n"
     ]
    }
   ],
   "source": [
    "# Test the Tavily search tool\n",
    "topic = \"retrieval-augmented generation applications\"\n",
    "\n",
    "tavily_results = research_tools.tavily_search_tool(topic)\n",
    "for item in tavily_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7f628",
   "metadata": {},
   "source": [
    "## Tool Mapping\n",
    "\n",
    "In the next cell you will define a dictionary that maps tool names (strings) to the actual Python functions. This allows the model to call tools by name during tool-calling. This dictionary will be used in your first graded function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada2e9cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 98,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Tool mapping\n",
    "TOOL_MAPPING = {\n",
    "    \"tavily_search_tool\": research_tools.tavily_search_tool,\n",
    "    \"arxiv_search_tool\": research_tools.arxiv_search_tool,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed9e5e",
   "metadata": {},
   "source": [
    "## Exercise 1: Generate Research Report with Tools\n",
    "**Goal:** Implement `generate_research_report_with_tools(prompt)`.\n",
    "In this exercise, you'll work on a function that generates a detailed research report with the assistance of online tools. Focus on setting up interaction with the language model and handling the responses effectively.\n",
    "\n",
    "## Key Hints\n",
    "\n",
    "### 1. Setting Up the Chat with the Language Model\n",
    "- **Tool Selection**: Ensure that the tools are automatically selected by the model. Look into how to set `tool_choice` to \"auto\" within the function call. A helpful resource can be found in [OpenAI‚Äôs Function Calling Documentation](https://platform.openai.com/docs/guides/function-calling#tool-choice).\n",
    "- **Parameter Configuration**: Consider the parameters already defined in your function, such as model, messages, and tools. Think about how these might be used in your setup.\n",
    "\n",
    "### 2. Recording Tool Call Results\n",
    "- **Understanding the `ChatCompletionMessage`** object will help you access the required attributes to save the messages. An example of `ChatCompletionMessage` looks like this: \n",
    "\n",
    "```python\n",
    "ChatCompletionMessage(\n",
    "    content=None,\n",
    "    refusal=None,\n",
    "    role='assistant',\n",
    "    annotations=[],\n",
    "    audio=None,\n",
    "    function_call=None,\n",
    "    tool_calls=[\n",
    "        ChatCompletionMessageFunctionToolCall(\n",
    "            id='call_ymMki5TBB91efJhMPjgoqjop',\n",
    "            function=Function(\n",
    "                arguments='{\"query\":\"radio observations of recurrent novae\",\"max_results\":5}',\n",
    "                name='arxiv_search_tool'\n",
    "            ),\n",
    "            type='function'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```\n",
    "Assuming that `msg` if of type `ChatCompletionMessage`, if you wanted to get the `name` of a `tool_call` you can do something like:\n",
    "```python\n",
    " for call in msg.tool_calls:\n",
    "    tool_name = call.function.name\n",
    "```\n",
    "Finally, the `result` variable will be created by actually calling the function associated with each tool (`tool_func`).\n",
    "\n",
    "By leveraging these hints, you'll work towards an implementation that enables robust data gathering and report generation through smart tool integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60ebc11",
   "metadata": {
    "deletable": false,
    "height": 1645,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: generate_research_report_with_tools\n",
    "def generate_research_report_with_tools(prompt: str, model: str = \"gpt-4o\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a research report using OpenAI's tool-calling with arXiv and Tavily tools.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "        model (str): OpenAI model name.\n",
    "\n",
    "    Returns:\n",
    "        str: Final assistant research report text.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a research assistant that can search the web and arXiv to write detailed, \"\n",
    "                \"accurate, and properly sourced research reports.\\n\\n\"\n",
    "                \"üîç Use tools when appropriate (e.g., to find scientific papers or web content).\\n\"\n",
    "                \"üìö Cite sources whenever relevant. Do NOT omit citations for brevity.\\n\"\n",
    "                \"üåê When possible, include full URLs (arXiv links, web sources, etc.).\\n\"\n",
    "                \"‚úçÔ∏è Use an academic tone, organize output into clearly labeled sections, and include \"\n",
    "                \"inline citations or footnotes as needed.\\n\"\n",
    "                \"üö´ Do not include placeholder text such as '(citation needed)' or '(citations omitted)'.\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # List of available tools\n",
    "    tools = [research_tools.arxiv_tool_def, research_tools.tavily_tool_def]\n",
    "\n",
    "    # Maximum number of turns\n",
    "    max_turns = 10\n",
    "    \n",
    "    # Iterate for max_turns iterations\n",
    "    for _ in range(max_turns):\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Chat with the LLM via the client and set the correct arguments. Hint: Their names match names of variables already defined.\n",
    "        # Make sure to let the LLM choose tools automatically. Hint: Look at the docs provided earlier!\n",
    "        response = CLIENT.chat.completions.create( \n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=1, \n",
    "        ) \n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Get the response from the LLM and append to messages\n",
    "        msg = response.choices[0].message \n",
    "        messages.append(msg) \n",
    "\n",
    "        # Stop when the assistant returns a final answer (no tool calls)\n",
    "        if not msg.tool_calls:      \n",
    "            final_text = msg.content\n",
    "            print(\"‚úÖ Final answer:\")\n",
    "            print(final_text)\n",
    "            break\n",
    "\n",
    "        # Execute tool calls and append results\n",
    "        for call in msg.tool_calls:\n",
    "            tool_name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "            print(f\"üõ†Ô∏è {tool_name}({args})\")\n",
    "\n",
    "            try:\n",
    "                tool_func = TOOL_MAPPING[tool_name]\n",
    "                result = tool_func(**args)\n",
    "            except Exception as e:\n",
    "                result = {\"error\": str(e)}\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "\n",
    "            # Keep track of tool use in a new message\n",
    "            new_msg = { \n",
    "                # Set role to \"tool\" (plain string) to signal a tool was used\n",
    "                \"role\": \"tool\",\n",
    "                # As stated in the markdown when inspecting the ChatCompletionMessage object \n",
    "                # every call has an attribute called id\n",
    "                \"tool_call_id\": call.id,\n",
    "                # The name of the tool was already defined above, use that variable\n",
    "                \"name\": tool_name,\n",
    "                # Pass the result of calling the tool to json.dumps\n",
    "                \"content\": json.dumps(result)\n",
    "            }\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Append to messages\n",
    "            messages.append(new_msg)\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee23d21",
   "metadata": {},
   "source": [
    "Run the following cell to check the correctness of your code. It might take a while so don't worry if it takes a couple of minutes to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af8aec5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è arxiv_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "‚úÖ Final answer:\n",
      "## Radio Observations of Recurrent Novae: A Review\n",
      "\n",
      "Recurrent novae are a subset of novae undergoing repeated outbursts due to the accretion of material from their companion stars. Their study involves observations across various electromagnetic spectrums, including radio frequencies. Recent advancements have provided significant insights into the characteristics and behaviors of these astronomical phenomena. Below are key findings from several research papers focusing on radio observations of recurrent novae.\n",
      "\n",
      "### General Overview of Recurrent Novae\n",
      "\n",
      "Koji Mukai's review on recurrent novae emphasizes the comprehensive study of these objects through multi-wavelength observations, including radio, optical, and X-ray emissions. The paper particularly focuses on the recurrent nova T Pyx, highlighting the complexity and variability of its envelope ejection phenomena, which deviate from the simpler, textbook descriptions of nova explosions [Mukai, 2014; arXiv:1407.4526v1](http://arxiv.org/abs/1407.4526v1).\n",
      "\n",
      "### Specific Observations and Discoveries\n",
      "\n",
      "1. **T Pyx Radio Observations**:\n",
      "   - Research led by Nelson et al. examined the 2011 outburst of T Pyx using radio observations from the Karl G. Jansky Very Large Array. The radio emission, consistent with thermal emission from the nova ejecta, revealed a surprisingly late rise in flux, suggesting that the bulk of the ejecta was either very cold or expanding slowly initially. The study concluded that a significant mass of ejecta, between \\(1-30 \\times 10^{-5}\\) solar masses, was involved in the eruption, which is higher than typical for recurrent novae [Nelson et al., 2012; arXiv:1211.3112v2](http://arxiv.org/abs/1211.3112v2).\n",
      "\n",
      "2. **V745 Sco Multiwavelength Analysis**:\n",
      "   - Delgado and Hernanz provided a comprehensive multiwavelength examination of the 2014 outburst of V745 Sco, a symbiotic recurrent nova. Incorporating radio and infrared data, alongside X-ray observations, this analysis offered insights into the shock dynamics and particle acceleration processes early in the eruption. The comparison with other symbiotic novae like RS Oph revealed parallels in the early shock evolution, marked by particle acceleration and rapid changes in plasma characteristics [Delgado & Hernanz, 2019; arXiv:1910.08940v1](http://arxiv.org/abs/1910.08940v1).\n",
      "\n",
      "3. **V3890 Sagitarii's Radio Emissions**:\n",
      "   - Recent observations by Nyamai et al. of V3890 Sagitarii post-2019 eruption showed double-peaked radio light curves attributed to synchrotron emissions. The dense circumstellar environment interacted with the expanding nova ejecta, creating significant radio luminosity variations. This study provided crucial data on the mass-loss rates and interactions of the nova's ejecta with the surrounding medium, further enriching our understanding of such systems and their potential links to supernovae progenitors [Nyamai et al., 2023; arXiv:2301.09116v1](http://arxiv.org/abs/2301.09116v1).\n",
      "\n",
      "4. **Hard X-Ray Emissions**:\n",
      "   - A study by Orio et al. analyzed archival ROSAT data of classical and recurrent novae, highlighting that most emit hard X-rays following outburst events. The emissions, mainly due to shocks within the nova ejecta, offer additional perspectives on the physical conditions and dynamics of the ejected materials. This was evident even years after the initial burst, especially if pre-existing circumstellar material or prolonged wind phases were involved [Orio et al., 2001; arXiv:astro-ph/0104219v1](http://arxiv.org/abs/astro-ph/0104219v1).\n",
      "\n",
      "### Conclusion and Future Directions\n",
      "\n",
      "Radio observations have proven to be invaluable in understanding the detailed processes and structures of recurrent novae. Continued advancements in radio astronomy, alongside complementary multiwavelength studies, are poised to unravel more mysteries from these fascinating celestial phenomena. Future research is likely to focus on enhancing the temporal resolution of observations to capture more transient and rapid events in recurrent novae evolutions. \n",
      "\n",
      "These studies not only enrich our understanding of novae themselves but also contribute to broader astrophysical contexts, such as the conditions leading to type Ia supernovae.\n",
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_generate_research_report_with_tools(generate_research_report_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb162d",
   "metadata": {},
   "source": [
    "## Exercise 2: Reflection + Rewrite\n",
    "\n",
    "**Goal:** Implement `reflection_and_rewrite(report)`.\n",
    "\n",
    "In this task, your goal is to develop a function that takes a report, analyzes it, generates a structured reflection, and produces an improved version of the report. This involves two main tasks: crafting a precise prompt and setting up a correctly configured response call to the language model.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### 1. Create a User Prompt\n",
    "\n",
    "- **Objective**: Guide the language model to output a structured response in JSON format.\n",
    "- **Format**: Ensure the output includes two keys, `\"reflection\"` and `\"revised_report\"`.\n",
    "- **Details**: Your reflection should cover strengths, limitations, suggestions, and opportunities. The revised report should incorporate these elements to improve clarity and academic tone.\n",
    "\n",
    "### 2. Configure the Response Call\n",
    "\n",
    "- **Parameters**: Use the specified model (e.g., `\"gpt-4o-mini\"`) and set the temperature equal to the `temperature` parameter of the graded function.\n",
    "- **Structure**: Make sure the response setup directs the model properly, ensuring the JSON format is adhered to without additional commentary.\n",
    "\n",
    "\n",
    "By implementing these steps, your function will effectively transform and improve the given reports. Handle JSON parsing carefully to ensure the output is valid and reliable. Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4585bcc6",
   "metadata": {
    "deletable": false,
    "height": 880,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reflection_and_rewrite\n",
    "def reflection_and_rewrite(report, model: str = \"gpt-4o-mini\", temperature: float = 0.3) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a structured reflection AND a revised research report.\n",
    "    Accepts raw text OR the messages list returned by generate_research_report_with_tools.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "          - \"reflection\": structured reflection text\n",
    "          - \"revised_report\": improved version of the input report\n",
    "    \"\"\"\n",
    "\n",
    "    # Input can be plain text or a list of messages, this function detects and parses accordingly\n",
    "    report = research_tools.parse_input(report)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the prompt. A multi-line f-string is typically used for this.\n",
    "    # Remember it should ask the model to output ONLY valid JSON with this structure:\n",
    "    # {{ \"reflection\": \"<text>\", \"revised_report\": \"<text>\" }}\n",
    "    user_prompt = f\"\"\"\n",
    "    Hi, You should generate a structured reflection and a revised research report, in the instructed JSON format.\n",
    "    \n",
    "    Format: \n",
    "    - Ensure the output includes two keys, \"reflection\" and \"revised_report\".\n",
    "    - Ouput ONLY valid JSON with this structure: {{ \"reflection\": \"<text>\", \"revised_report\": \"<text>\" }}\n",
    "    \n",
    "    Details: Your reflection should cover strengths, limitations, suggestions, and opportunities. The revised report should incorporate these elements to improve clarity and academic tone.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a response from the LLM\n",
    "    response = CLIENT.chat.completions.create( \n",
    "        # Pass in the model\n",
    "        model=model,\n",
    "        messages=[ \n",
    "            # System prompt is already defined\n",
    "            {\"role\": \"system\", \"content\": \"You are an academic reviewer and editor.\"},\n",
    "            # Add user prompt\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        # Set the temperature equal to the temperature parameter passed to the function\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract output\n",
    "    llm_output = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Check if output is valid JSON\n",
    "    try:\n",
    "        data = json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"The output of the LLM was not valid JSON. Adjust your prompt.\")\n",
    "\n",
    "    return {\n",
    "        \"reflection\": str(data.get(\"reflection\", \"\")).strip(),\n",
    "        \"revised_report\": str(data.get(\"revised_report\", \"\")).strip(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a563b04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_reflection_and_rewrite(reflection_and_rewrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210d211",
   "metadata": {},
   "source": [
    "## Exercise 3: Convert Report to HTML\n",
    "**Goal:** Implement `convert_report_to_html(report)`.\n",
    "This exercise focuses on transforming a plain text research report into a well-structured HTML document. You will build a function to facilitate this conversion using a language model.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### 1. Create a User Prompt\n",
    "- **Objective**: Instruct the model to transform plain text into HTML structure.\n",
    "- **Format**: Ensure the output is valid, clean HTML with appropriate section headers, formatted paragraphs, and clickable links.\n",
    "- **Details**: Preserve the citation style and request that the model responds only with HTML, without additional commentary.\n",
    "\n",
    "### 2. Configure the Response Call\n",
    "- **Parameters**: Use the specified model (e.g., `\"gpt-4o\"`) and set an appropriate temperature to balance creativity and accuracy.\n",
    "- **Structure**: Configure the `CLIENT.chat.completions.create` call properly, using both system and user prompts to ensure a clear and focused task description.\n",
    "\n",
    "By following these steps, you'll effectively convert plaintext reports into formatted HTML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7548464",
   "metadata": {
    "deletable": false,
    "height": 489,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convert_report_to_html\n",
    "def convert_report_to_html(report, model: str = \"gpt-4o\", temperature: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Converts a plaintext research report into a styled HTML page using OpenAI.\n",
    "    Accepts raw text OR the messages list from the tool-calling step.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input can be plain text or a list of messages, this function detects and parses accordingly\n",
    "    report = research_tools.parse_input(report)\n",
    "\n",
    "    # System prompt is already provided\n",
    "    system_prompt = \"You convert plaintext reports into full clean HTML documents.\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Build the user prompt instructing the model to return ONLY valid HTML\n",
    "    user_prompt = f\"\"\"\n",
    "    Hi, you should convert the provided plaintext research report into a styled HTML page (should strictly follow HTML structure).\n",
    "    Format: Ensure the output is valid, clean HTML with appropriate section headers, formatted paragraphs, and clickable links.\n",
    "    Details: Preserve the citation style and request that the model responds only with HTML, without additional commentary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the LLM by interacting with the CLIENT. \n",
    "    # Remember to set the correct values for the model, messages (system and user prompts) and temperature\n",
    "    response = CLIENT.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "        {\"role\" : \"user\", \"content\" : user_prompt}\n",
    "    ],\n",
    "    temperature = temperature\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract the HTML from the assistant message\n",
    "    html = response.choices[0].message.content.strip()  \n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe3c9c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_convert_report_to_html(convert_report_to_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f5e51",
   "metadata": {},
   "source": [
    "### üöÄ End-to-End Pipeline\n",
    "\n",
    "Run this cell to execute the full workflow:\n",
    "\n",
    "1. Generate a research report (tools).\n",
    "2. Reflect on the report.\n",
    "3. Convert the report to HTML.\n",
    "\n",
    "> You should see the rendered HTML below and two concise reflections in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f07e12e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 387
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è arxiv_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "üõ†Ô∏è tavily_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "‚úÖ Final answer:\n",
      "### Introduction\n",
      "\n",
      "Recurrent novae (RNe) are a subtype of cataclysmic variable stars characterized by recurrent thermonuclear eruptions on the surface of a white dwarf. These events are triggered by the accretion of material from a companion star. Recurrent novae can undergo multiple outbursts over a century, making them valuable subjects for study, particularly using radio observations, which provide insights into the dynamics and properties of the ejected material.\n",
      "\n",
      "### Recent Radio Observations of Recurrent Novae\n",
      "\n",
      "#### MeerKAT Observations of V3890 Sgr and RS Oph\n",
      "\n",
      "A recent study involving the MeerKAT radio telescope focused on the recurrent novae V3890 Sagittarii and RS Ophiuchi. These observations aimed to investigate the interaction between the nova ejecta and the surrounding medium. These novae have multiple recorded eruptions within a century, offering a unique opportunity to study the evolution and impact of repeated outbursts [ADS Source](https://ui.adsabs.harvard.edu/abs/2023afas.confE..56N/abstract).\n",
      "\n",
      "#### 2011 Outburst of T Pyxidis\n",
      "\n",
      "The 2011 outburst of the recurrent nova T Pyxidis was observed using the Karl G. Jansky Very Large Array. These observations helped trace the evolution of the nova ejecta, which is consistent with thermal emission. The findings hinted at a complex mass-loss history, contributing to our understanding of this somewhat unusual and poorly understood recurrent nova. The data from this study were published in *The Astrophysical Journal* [ADS Source](https://ui.adsabs.harvard.edu/abs/2014ApJ...785...78N/abstract).\n",
      "\n",
      "#### Low-Frequency Observations of RS Ophiuchi\n",
      "\n",
      "In 2021, a low-frequency radio observational study was conducted during the outburst of the recurrent nova RS Ophiuchi. This study provided new data on the lowest frequency emissions observed from such an event, revealing important details about the non-thermal processes likely involved in the nova's radio emissions [MNRAS Source](https://academic.oup.com/mnras/article/523/1/132/7159730).\n",
      "\n",
      "### Early Radio Detection\n",
      "\n",
      "The first radio detection of an outburst from a recurrent nova was also related to RS Ophiuchi. This landmark observation suggested a non-thermal origin for the radio emission, distinguishing it from the classical novae and providing early critical insights into recurrent nova mechanisms [Nature Source](https://www.nature.com/articles/315306a0).\n",
      "\n",
      "### Broader Context and Historical Perspective\n",
      "\n",
      "The study of novae at radio wavelengths has a rich history, beginning in the 1970s. Initially centered on thermal free-free emission signatures, the field has evolved significantly. The examination of both classical and recurrent novae provides critical insights into their emission mechanisms, the nature of the ejecta, and their interactions with surrounding environments [IOP Source](https://iopscience.iop.org/article/10.3847/1538-4365/ac24ab/pdf).\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Radio observations of recurrent novae are vital for understanding the dynamics of these stellar explosions. By analyzing the ejected material and its interaction with the environment, these studies help decipher the complex behaviors of these transient astronomical phenomena. Each nova provides unique insights, contributing to the broader astrophysical knowledge of accreting binary systems.\n",
      "=== Research Report (preliminary) ===\n",
      "\n",
      "### Introduction\n",
      "\n",
      "Recurrent novae (RNe) are a subtype of cataclysmic variable stars characterized by recurrent thermonuclear eruptions on the surface of a white dwarf. These events are triggered by the accretion of material from a companion star. Recurrent novae can undergo multiple outbursts over a century, making them valuable subjects for study, particularly using radio observations, which provide insights into the dynamics and properties of the ejected material.\n",
      "\n",
      "### Recent Radio Observations of Recurrent Novae\n",
      "\n",
      "#### MeerKAT Observations of V3890 Sgr and RS Oph\n",
      "\n",
      "A recent study involving the MeerKAT radio telescope focused on the recurrent novae V3890 Sagittarii and RS Ophiuchi. These observations aimed to investigate the interaction between the nova ejecta and the surrounding medium. These novae have multiple recorded eruptions within a century, offering a unique opportunity to study the evolution and impact of repeated outbursts [ADS Source](https://ui.adsabs.harvard.edu/abs/2023afas.confE..56N/abstract).\n",
      "\n",
      "#### 2011 Outburst of T Pyxidis\n",
      "\n",
      "The 2011 outburst of the recurrent nova T Pyxidis was observed using the Karl G. Jansky Very Large Array. These observations helped trace the evolution of the nova ejecta, which is consistent with thermal emission. The findings hinted at a complex mass-loss history, contributing to our understanding of this somewhat unusual and poorly understood recurrent nova. The data from this study were published in *The Astrophysical Journal* [ADS Source](https://ui.adsabs.harvard.edu/abs/2014ApJ...785...78N/abstract).\n",
      "\n",
      "#### Low-Frequency Observations of RS Ophiuchi\n",
      "\n",
      "In 2021, a low-frequency radio observational study was conducted during the outburst of the recurrent nova RS Ophiuchi. This study provided new data on the lowest frequency emissions observed from such an event, revealing important details about the non-thermal processes likely involved in the nova's radio emissions [MNRAS Source](https://academic.oup.com/mnras/article/523/1/132/7159730).\n",
      "\n",
      "### Early Radio Detection\n",
      "\n",
      "The first radio detection of an outburst from a recurrent nova was also related to RS Ophiuchi. This landmark observation suggested a non-thermal origin for the radio emission, distinguishing it from the classical novae and providing early critical insights into recurrent nova mechanisms [Nature Source](https://www.nature.com/articles/315306a0).\n",
      "\n",
      "### Broader Context and Historical Perspective\n",
      "\n",
      "The study of novae at radio wavelengths has a rich history, beginning in the 1970s. Initially centered on thermal free-free emission signatures, the field has evolved significantly. The examination of both classical and recurrent novae provides critical insights into their emission mechanisms, the nature of the ejecta, and their interactions with surrounding environments [IOP Source](https://iopscience.iop.org/article/10.3847/1538-4365/ac24ab/pdf).\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Radio observations of recurrent novae are vital for understanding the dynamics of these stellar explosions. By analyzing the ejected material and its interaction with the environment, these studies help decipher the complex behaviors of these transient astronomical phenomena. Each nova provides unique insights, contributing to the broader astrophysical knowledge of accreting binary systems.\n",
      "=== Reflection on Report ===\n",
      "\n",
      "The research report demonstrates several strengths, including a clear research question, a well-defined methodology, and a thorough literature review that contextualizes the study within existing knowledge. However, there are limitations, such as a small sample size and potential biases in data collection that could affect the generalizability of the findings. Suggestions for improvement include expanding the sample size, employing a more diverse participant pool, and enhancing the data analysis section to provide deeper insights. Opportunities for future research could involve longitudinal studies to track changes over time or comparative studies across different demographics to enrich the understanding of the topic. \n",
      "\n",
      "=== Revised Report ===\n",
      "\n",
      "Title: [Revised Title]\n",
      "\n",
      "Abstract: This study investigates [insert research question] using a comprehensive methodology that includes [insert methods]. The findings indicate [insert key findings], contributing to the existing literature on [insert relevant field]. \n",
      "\n",
      "1. Introduction\n",
      "   The introduction outlines the significance of the research question and its relevance to [insert field]. A review of the literature highlights gaps that this study aims to address.\n",
      "\n",
      "2. Methodology\n",
      "   A detailed description of the methodology is provided, including participant selection, data collection methods, and analysis techniques. The study employed [insert methods], ensuring a systematic approach to data gathering.\n",
      "\n",
      "3. Results\n",
      "   The results section presents the findings in a clear and organized manner, utilizing tables and figures where appropriate to enhance understanding.\n",
      "\n",
      "4. Discussion\n",
      "   This section interprets the results in the context of existing literature, discussing implications, limitations, and potential biases. Suggestions for future research are also outlined, emphasizing the need for larger and more diverse samples.\n",
      "\n",
      "5. Conclusion\n",
      "   The conclusion summarizes the key findings and their significance, reiterating the importance of further research in this area.\n",
      "\n",
      "References: [Insert updated references in appropriate format] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generated HTML (preview) ===\n",
      "\n",
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Research Report</title>\n",
      "    <style>\n",
      "        body {\n",
      "            font-family: Arial, sans-serif;\n",
      "            line-height: 1.6;\n",
      "            margin: 20px;\n",
      "        }\n",
      "        h1, h2, h3 {\n",
      "            color: #333;\n",
      "        }\n",
      "        a {\n",
      "            color: #1a0dab;\n",
      "            text-decoration: none;\n",
      "        }\n",
      "        a:hover {\n",
      "            text-decoration: underline;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "\n",
      "    <header>\n",
      "        <h1>Research Report \n",
      "... [truncated]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Research Report</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "            line-height: 1.6;\n",
       "            margin: 20px;\n",
       "        }\n",
       "        h1, h2, h3 {\n",
       "            color: #333;\n",
       "        }\n",
       "        a {\n",
       "            color: #1a0dab;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "        a:hover {\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "\n",
       "    <header>\n",
       "        <h1>Research Report on Climate Change</h1>\n",
       "        <p>Author: Jane Doe</p>\n",
       "        <p>Date: October 2023</p>\n",
       "    </header>\n",
       "\n",
       "    <section>\n",
       "        <h2>Abstract</h2>\n",
       "        <p>This research report examines the impacts of climate change on global weather patterns and ecosystems. It explores the causes of climate change, its effects on the environment, and potential solutions to mitigate its impact.</p>\n",
       "    </section>\n",
       "\n",
       "    <section>\n",
       "        <h2>Introduction</h2>\n",
       "        <p>Climate change is a significant and lasting change in the statistical distribution of weather patterns over periods ranging from decades to millions of years. It can be caused by natural factors, such as changes in solar radiation, or human activities, such as the burning of fossil fuels.</p>\n",
       "    </section>\n",
       "\n",
       "    <section>\n",
       "        <h2>Causes of Climate Change</h2>\n",
       "        <p>Human activities, particularly the burning of fossil fuels and deforestation, have significantly increased the concentration of greenhouse gases in the atmosphere. This has led to an enhanced greenhouse effect, resulting in global warming.</p>\n",
       "        <p>For more information, visit the <a href=\"https://www.ipcc.ch\" target=\"_blank\">Intergovernmental Panel on Climate Change (IPCC)</a> website.</p>\n",
       "    </section>\n",
       "\n",
       "    <section>\n",
       "        <h2>Effects on the Environment</h2>\n",
       "        <p>Climate change has led to more frequent and severe weather events, such as hurricanes, droughts, and floods. It also affects biodiversity, leading to habitat loss and species extinction.</p>\n",
       "    </section>\n",
       "\n",
       "    <section>\n",
       "        <h2>Potential Solutions</h2>\n",
       "        <p>To mitigate the impacts of climate change, it is crucial to reduce greenhouse gas emissions. This can be achieved through the adoption of renewable energy sources, energy efficiency measures, and reforestation efforts.</p>\n",
       "    </section>\n",
       "\n",
       "    <section>\n",
       "        <h2>Conclusion</h2>\n",
       "        <p>Climate change is a pressing global issue that requires immediate action. By understanding its causes and effects, and implementing effective solutions, we can work towards a sustainable future.</p>\n",
       "    </section>\n",
       "\n",
       "    <footer>\n",
       "        <p>References:</p>\n",
       "        <ul>\n",
       "            <li>Intergovernmental Panel on Climate Change. (2023). <em>Climate Change 2023: The Physical Science Basis</em>. Retrieved from <a href=\"https://www.ipcc.ch/report/ar6/wg1/\" target=\"_blank\">https://www.ipcc.ch/report/ar6/wg1/</a></li>\n",
       "            <li>National Aeronautics and Space Administration. (2023). <em>Global Climate Change: Vital Signs of the Planet</em>. Retrieved from <a href=\"https://climate.nasa.gov/\" target=\"_blank\">https://climate.nasa.gov/</a></li>\n",
       "        </ul>\n",
       "    </footer>\n",
       "\n",
       "</body>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Research with tools\n",
    "prompt_ = \"Radio observations of recurrent novae\"\n",
    "preliminary_report = generate_research_report_with_tools(prompt_)\n",
    "print(\"=== Research Report (preliminary) ===\\n\")\n",
    "print(preliminary_report)\n",
    "\n",
    "# 2) Reflection on the report (use the final TEXT to avoid ambiguity)\n",
    "reflection_text = reflection_and_rewrite(preliminary_report)   # <-- pass text, not messages\n",
    "print(\"=== Reflection on Report ===\\n\")\n",
    "print(reflection_text['reflection'], \"\\n\")\n",
    "print(\"=== Revised Report ===\\n\")\n",
    "print(reflection_text['revised_report'], \"\\n\")\n",
    "\n",
    "\n",
    "# 3) Convert the report to HTML (use the TEXT and correct function name)\n",
    "html = convert_report_to_html(reflection_text['revised_report'])\n",
    "\n",
    "print(\"=== Generated HTML (preview) ===\\n\")\n",
    "print((html or \"\")[:600], \"\\n... [truncated]\\n\")\n",
    "\n",
    "# 4) Display full HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00231efc",
   "metadata": {},
   "source": [
    "### üìå ‚ÄúExpected Output‚Äù note (for the notebook text cell)\n",
    "\n",
    "- `generate_research_report_with_tools` should return a **non-trivial string** (> 50 chars).\n",
    "\n",
    "- `reflection_and_rewrite` should return a **dict** with **'reflection'** and **'revised\\_report'** (both strings). The reflection should **mention** the four sections (Strengths, Limitations, Suggestions, Opportunities).\n",
    "\n",
    "- `convert_report_to_html` should return a **string that looks like HTML** (e.g., includes `<html>`, `<h1>`, `<p>`, or closing tags).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaad9ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Wrap-Up\n",
    "\n",
    "You built a mini research agent that can:\n",
    "- üîé call tools (arXiv + Tavily),\n",
    "- üß† reflect on its own output,\n",
    "- üì∞ publish a clean HTML report.\n",
    "\n",
    "Great job!\n",
    "\n",
    "### What to Submit\n",
    "- Your notebook with Exercise 1‚Äì3 completed.\n",
    "\n",
    "### Troubleshooting (quick)\n",
    "- **Model/tool-call loop stalls?** Lower `max_turns` or print intermediate messages.\n",
    "- **HTML looks odd?** Re-run conversion with a fresh assistant response.\n",
    "\n",
    "**You‚Äôre done‚Äînice work!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678071d",
   "metadata": {},
   "source": [
    "## Check grading feedback\n",
    "\n",
    "If you have collapsed the right panel to have more screen space for your code, as shown below:\n",
    "\n",
    "<img src=\"./images/collapsed.png\" alt=\"Collapsed Image\" width=\"800\" height=\"400\"/>\n",
    "\n",
    "You can click on the left-facing arrow button (highlighted in red) to view feedback for your submission after submitting it for grading. Once expanded, it should display like this:\n",
    "\n",
    "<img src=\"./images/expanded.png\" alt=\"Expanded Image\" width=\"800\" height=\"400\"/>"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
